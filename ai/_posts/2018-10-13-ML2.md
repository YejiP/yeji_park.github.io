# **Logistic regression** **정리**

- 분류를 위해 사용한다. 

Binary class/ Multi-class Classification 가 있다.

<img src = "https://user-images.githubusercontent.com/37058233/103741610-bcc1a800-503c-11eb-8cfb-e878d999d8db.png" width = 400px alt = "classification" >

**Y = f(x)** 라는, 앞서 배운, 선형회귀로 예측한다예 쳤을 때, x가 무한대로 갈 때, y의 값이 무한한 음수로가게 된다.

그러나, 위의 classification 모델에서는, y 값은 0,1 두가지 숫자로만 표현이 된다. 따라서, f(x)의 실효성이 없어지게 된다.

이 문제를 해결하기 위해서, 모든 실수를 정의 역으로 갖고, 치역은 0에서 1을 갖는 함수에 이 f(x) 의 결과를 대입한다. 

이 함수는 바로 **시그모이드 함수**이다. 

시그모이드 함수는, 이 f(x)의 결과값을 인풋으로 해서, 아웃풋을 출력한다. 이것을 입체적으로, 좌표적으로 생각해보면, 시그모이드 함수는, x,y 평면에서의 특정한 인풋을 가지고 어떤 값을 내는데 , 그 값이 z축으로 내질 수 있다. 

<img src = "https://user-images.githubusercontent.com/37058233/103741741-f7c3db80-503c-11eb-9bf8-3ec979b71b15.png" alt = "sigmoid" width = 300px>

z축은, 음의 무한대, 양의 무한대로 갈 때, 각각 0 과 1 에 수렴한다. F(x) 의 z 값은 0이다. 

Malignant0 는, 이 시그모이드 함수의 위에 있고, malignant1 은 이 시그모이드 함수의 아래에 있다.!

**그럼 이제, 수식으로 생각해보자.** 

## **Logistic regression:**

<img src = "https://user-images.githubusercontent.com/37058233/103742175-bf70cd00-503d-11eb-8ce0-69b2687123a9.png" width = 400px>

 

<img src="https://user-images.githubusercontent.com/37058233/103742316-f5ae4c80-503d-11eb-8f1d-2eb816593b68.png" width = 400px>

<img src="https://user-images.githubusercontent.com/37058233/103742367-0e1e6700-503e-11eb-934c-20696b01898e.png" width = 500px>

시그모이드 함수에 넣은게 저 하늘색 형광펜이다. 시그모이드보다 아래있으면 1, 시그모이드보다 위에 있으면 0이다. 

## **Cost function**

<img src="https://user-images.githubusercontent.com/37058233/103742507-4625aa00-503e-11eb-8938-9e8585c54b5a.png" width=200px>

Y가 0, 1 일때 구분하지 않고, 한번에 나타낸 것 

<img src="https://user-images.githubusercontent.com/37058233/103742564-60f81e80-503e-11eb-9415-acc880abb537.png" width = 400px>

0,1 일때 각각 한 항이 없어져 한 항만 남는다. 

<img src="https://user-images.githubusercontent.com/37058233/103742607-72412b00-503e-11eb-906d-6897c6eca359.png" width=250px>

 

Gradient descendant 는, cost function 미분한것. 

세타에 대해 미분을 하면 다음과 같다. 

<img src="https://user-images.githubusercontent.com/37058233/103742814-c3e9b580-503e-11eb-8d68-54682dbb9cf4.png" width=400px>