# **Decision tree**

## **ID3 algorithm**



<img src="https://user-images.githubusercontent.com/37058233/103745476-e41b7380-5042-11eb-9d82-c5a99c2f65be.png" width=300>

엔트로피가 1 이 뒤면 가장 높다.

반반 섞여있으면 1, 한 종류만 있으면 0이다.



*우리가 해결하고 싶은 문제 : play no/yes를 나누는 가장 효율적인 방법을 알고싶다. 

Outlook, temp, humidity, windy 총 이 네가지로 분류될 수 있을 때, 어떤것을 기준으로 처음 나누는 것이 가장 좋을까?

<img src="https://user-images.githubusercontent.com/37058233/103745507-f3022600-5042-11eb-9e3e-8c5f585b7b50.png" width = 200>

<img src="https://user-images.githubusercontent.com/37058233/103745531-fc8b8e00-5042-11eb-9d6d-bb318e6fa0ea.png" width = 200>

여기서 entropy 구하기.

E(outlook = sunny) = 

-2/5*log(2/5) –3/5*log(3/5) = 0.971

E(outlook = overcast) = -1*log(1) – 0*log(0)=0

E(outlook = rainy) = 

-2/5*log(2/5) –3/5*log(3/5) = 0.971

이 각각의 숫자에 전체에서 차지하는 비율을 곱해준다. 

그러면 0.693이 나온다.

 

나눠지지 않았을 때의 엔트로피를 구한다.

그리고, 각각 feature을 기준으로 나눴을 때의 엔트로피를 구한다.

이 둘의 차이가 가장 높을 것을 고른다.

그것을 첫번째 tree 나누는 기준으로 삼는다. 

이제 또 같은 방식을 적용해서 똑같이 나눠준다. 

<img src="https://user-images.githubusercontent.com/37058233/103745584-13ca7b80-5043-11eb-9c9f-0a7603c1f040.png" width=350>

 

regression tree때는?

이때는 엔트로피 gain 못쓴다. 대신, 분산을 사용한다. 예를 들어, x,y,z, price 있다. 그럼, price 의 분산이 있다. 두개로 쪼갰을 때, 각각의 분산은 작아진다. 작아지는 것을 트리의 기준으로 삼는다. 

 

 

## **CART algorithm**

Gini index를 사용한다.

<img src="https://user-images.githubusercontent.com/37058233/103745609-1dec7a00-5043-11eb-8215-1fdba364e5fb.png" width=250>

K = class의 개수!

 

## **Bagging and boosting**

<img src="https://user-images.githubusercontent.com/37058233/103745631-2644b500-5043-11eb-842c-94bb08574ab0.png" width=350>

n개의 데이터가 있을 때, 이 n개의 데이터에서, 

k개 샘플을 취하는데, 중복을 허용해서 k개의 샘플을 취한다. (1번을 뽑았다가, 다시 1번 뽑기 가능.) 그럼 하나의 학습 데이터에서 여러개의 샘플 생긴다. 그리고 각각 가진 데이터 조금씩 다르다. 그러면 그 모델을 여러가지 만든다. 데이터가 다르니까 모델들이 다른 게 나온다. 그럼 예측 모델을 잘 융합해(평균으로) 최종모델을 만든다.

 

## **Random forest**

다양한 트리를 만들 수 있게 해준다. 설명력이 너무 높은 변수가 있다면, 비슷한 트리만 만들어지기 위해서, feature 또한 sampling해주어서 여러가지 트리 모델을 만들어서 합쳐주는 것이다.  (bagging은 observation 만 sampling 하는데, random forest는 observation + features 를 sampling 한다.)

 

*저번 학기 decision tree

library(rpart)

\# 예측하고 싶은 변수 ~ 어떤 변수들로 예측할 것인지

loan_model <- rpart(outcome ~ loan_amount + credit_score, data = loans, method = "class", control = rpart.control(cp = 0))

 